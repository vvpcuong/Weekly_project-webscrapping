{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Webscrapping_tiki.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16xCirxPGJvI",
        "outputId": "5ef06ed2-0359-4dfa-abe5-e8a3f62f8522"
      },
      "source": [
        "!pip install selenium"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB4ov5vJHcIH",
        "outputId": "f8fb82f4-16f6-430a-ae28-8261c1196137"
      },
      "source": [
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install webdriver-manager"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (89.0.4389.90-0ubuntu0.18.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: crayons in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (0.4.0)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from crayons->webdriver-manager) (0.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I50jtWYNHjwT"
      },
      "source": [
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "# Set driver for Chrome\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('-headless') # since we run selenium on Google Colab so we don't want a chrome browser opens, so it will run in the background\n",
        "options.add_argument('-no-sandbox')\n",
        "options.add_argument('-disable-dev-shm-usage')\n",
        "options.add_argument(\"--incognito\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLpBUdPM_fpm"
      },
      "source": [
        "def selenium_scrap(tiki_url):\n",
        "  driver = webdriver.Chrome('chromedriver',options=options)        # Define the chrome drivers with setting options we define above  \n",
        "  driver.implicitly_wait(60)                                       # We let selenium to wait for 30 seconds for all javascript script done before return the result of HTML\n",
        "                                     \n",
        "  driver.get(tiki_url)                                             # Open the browser again to get web page\n",
        "  html_data = driver.page_source                                   # After driver.get() is done, you can get back HTML string by using .page_source\n",
        "  driver.close()                                                   # Close the driver after retrieving the web page\n",
        "                                        \n",
        "\n",
        "  soup = BeautifulSoup(html_data, 'html.parser')                   # do your beautifulsoup business like the usual\n",
        "  products_a = soup.find_all('a', {'class':'product-item'})\n",
        "  jasonproduct = soup.find_all('script', {\"type\":\"application/ld+json\"})\n",
        "  print('Total product in page: ',len(products_a)) #numbers of product.\n",
        "  page_product = []\n",
        "\n",
        "  for item in range(len(products_a)):\n",
        "    product_info_dict = {}\n",
        "    each_product_thumbnail_info = products_a[item].div.find_all('div')\n",
        "      # product image url\n",
        "    product_image_url = each_product_thumbnail_info[0].img['src']\n",
        "    product_info_dict['Image url'] = product_image_url\n",
        "      # product class info\n",
        "    product_name = products_a[item].find('div',{'class':'name'}).text\n",
        "    product_info_dict['Product name'] = product_name\n",
        "    product_price_discount = products_a[item].find('div',{'class':'price-discount__price'}).text\n",
        "    product_info_dict['Price after discount'] = product_price_discount\n",
        "    \n",
        "    try:\n",
        "      assert products_a[item].find('div',{'class':'price-discount__discount'}).text.strip('-') != None\n",
        "    except:\n",
        "      product_info_dict['Discount'] = 'None'\n",
        "    else:\n",
        "      product_discount = products_a[item].find('div',{'class':'price-discount__discount'}).text.strip('-')\n",
        "      product_info_dict['Discount'] = product_discount\n",
        "      \n",
        "    try:\n",
        "      assert products_a[item].find('div',{'class':'review'}).text.strip('(').strip(')') != None\n",
        "    except:\n",
        "      product_info_dict['Review count'] = 0\n",
        "    else:\n",
        "      product_review = products_a[item].find('div',{'class':'review'}).text.strip('(').strip(')')\n",
        "      product_info_dict['Review count'] = product_review\n",
        "\n",
        "   \n",
        "   \n",
        "      #Product SKU\n",
        "    a = jasonproduct[item+1].text\n",
        "    bdict = json.loads(a)\n",
        "    product_info_dict['sku'] = bdict['sku']\n",
        "    product_info_dict['description'] = bdict['description']\n",
        "    product_info_dict['URL'] = bdict['url']\n",
        "    \n",
        "      \n",
        "      # Append to page_product\n",
        "      \n",
        "    page_product.append(product_info_dict)\n",
        "    \n",
        "  return page_product"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWQW1WvWltiI"
      },
      "source": [
        "def scrapper_tiki(url):\n",
        "    page_number = 1\n",
        "    tiki_url = url\n",
        "\n",
        "\n",
        "    first,second = tiki_url.split('?')\n",
        "\n",
        "    category_scrap = []\n",
        "    while True:\n",
        "      page = f'?page={page_number}'\n",
        "      tiki_url = first+page+second\n",
        "      page_product = selenium_scrap(tiki_url)\n",
        "      if len(page_product) == 0:\n",
        "        break\n",
        "      category_scrap.extend(page_product)\n",
        "      page_number+=1\n",
        "      time.sleep(5)\n",
        "\n",
        "\n",
        "    data = pd.DataFrame(data = category_scrap, columns = category_scrap[0].keys())\n",
        "\n",
        "    # it should store a \"result.csv\" in your current folder, you can download it to store it\n",
        "    data.to_csv(\"./result.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khulDUI0uPVp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "9c703bef-0e60-4f59-f806-2e88695b4619"
      },
      "source": [
        "scrapper_tiki('https://tiki.vn/laptop/c8095?&src=static_block')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9b6d143b9905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscrapper_tiki\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://tiki.vn/laptop/c8095?&src=static_block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-401150c7e1ec>\u001b[0m in \u001b[0;36mscrapper_tiki\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'?page={page_number}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mtiki_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mpage_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselenium_scrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiki_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_product\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6d1db0102ff4>\u001b[0m in \u001b[0;36mselenium_scrap\u001b[0;34m(tiki_url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselenium_scrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiki_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chromedriver'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Define the chrome drivers with setting options we define above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m                                       \u001b[0;31m# We let selenium to wait for 30 seconds for all javascript script done before return the result of HTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiki_url\u001b[0m\u001b[0;34m)\u001b[0m                                             \u001b[0;31m# Open the browser again to get web page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'webdriver' is not defined"
          ]
        }
      ]
    }
  ]
}